{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dhq_df = pd.read_csv(\"../datasets/private_data/dhq_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "683"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dhq_df['DHQarticle-id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "723"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the XML namespaces\n",
    "namespaces = {\n",
    "    'tei': \"http://www.tei-c.org/ns/1.0\",\n",
    "    'dhq': \"http://www.digitalhumanities.org/ns/dhq\",\n",
    "    'xml': \"http://www.w3.org/XML/1998/namespace\"\n",
    "}\n",
    "directory_path = \"../datasets/private_data/dhq/articles/\"\n",
    "all_data = []\n",
    "# xml_files = [os.path.join(directory_apth, file_name) for file_name in os.listdir(directory_apth) if file_name.endswith(\".xml\")]\n",
    "\n",
    "exclude = ['old', 'converted', 'dhq', 'sample', 'recovered', 'test', 'walsh']\n",
    "\n",
    "# List only XML files\n",
    "xml_files = [os.path.join(dp, f) for dp, dn, filenames in os.walk(directory_path) for f in filenames \n",
    "             if f.endswith('.xml') \n",
    "             and not any(ex_str in f for ex_str in exclude) \n",
    "             and not f.startswith('999')]\n",
    "\n",
    "len(xml_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_xml_files(xml_files, output_path):\n",
    "    if os.path.exists(output_path):\n",
    "        final_df = pd.read_csv(output_path)\n",
    "    else:\n",
    "        for file_name in tqdm(xml_files, desc=\"Processing XML files\"):\n",
    "        \n",
    "            with open(file_name, 'r', encoding='utf-8') as f:\n",
    "                file_content = f.read().strip()\n",
    "                \n",
    "            if file_content == '<?xml version=\"1.0\" encoding=\"UTF-8\"?>':\n",
    "                continue  # Skip to the next file if the content is just the XML declaration\n",
    "            \n",
    "            try:\n",
    "                tree = ET.parse(file_name)\n",
    "                root = tree.getroot()\n",
    "            except ET.ParseError:\n",
    "                print(f\"Error parsing {file_name}. Skipping...\")\n",
    "                continue\n",
    "\n",
    "            # Extracting the required data with checks to avoid errors\n",
    "            base_data = {\n",
    "                'DHQarticle-id': root.find(\".//tei:publicationStmt/tei:idno[@type='DHQarticle-id']\", namespaces=namespaces).text if root.find(\".//tei:publicationStmt/tei:idno[@type='DHQarticle-id']\", namespaces=namespaces) is not None else None,\n",
    "                'volume': root.find(\".//tei:publicationStmt/tei:idno[@type='volume']\", namespaces=namespaces).text if root.find(\".//tei:publicationStmt/tei:idno[@type='volume']\", namespaces=namespaces) is not None else None,\n",
    "                'issue': root.find(\".//tei:publicationStmt/tei:idno[@type='issue']\", namespaces=namespaces).text if root.find(\".//tei:publicationStmt/tei:idno[@type='issue']\", namespaces=namespaces) is not None else None,\n",
    "                'articleType': root.find(\".//tei:publicationStmt/dhq:articleType\", namespaces=namespaces).text if root.find(\".//tei:publicationStmt/dhq:articleType\", namespaces=namespaces) is not None else None,\n",
    "                'date_when': root.find(\".//tei:publicationStmt/tei:date\", namespaces=namespaces).text if root.find(\".//tei:publicationStmt/tei:date\", namespaces=namespaces) is not None else None,\n",
    "                'dhq_keywords': root.find(\".//tei:encodingDesc/tei:classDecl/tei:taxonomy[@xml:id='dhq_keywords']/tei:bibl\", namespaces=namespaces).text if root.find(\".//tei:encodingDesc/tei:classDecl/tei:taxonomy[@xml:id='dhq_keywords']/tei:bibl\", namespaces=namespaces) is not None else None,\n",
    "                'language_ident': root.find(\".//tei:profileDesc/tei:langUsage/tei:language\", namespaces=namespaces).attrib['ident'] if root.find(\".//tei:profileDesc/tei:langUsage/tei:language\", namespaces=namespaces) is not None else None,\n",
    "                'dhq_abstract': root.find(\".//tei:text/tei:front/dhq:abstract/tei:p\", namespaces=namespaces).text if root.find(\".//tei:text/tei:front/dhq:abstract/tei:p\", namespaces=namespaces) is not None else None,\n",
    "                'file_name': file_name\n",
    "            }\n",
    "\n",
    "            # Extract title\n",
    "            title_element = root.find(\".//tei:titleStmt/tei:title\", namespaces=namespaces)\n",
    "            if title_element is not None:\n",
    "                # Concatenate all text and tail components of the element and its descendants\n",
    "                title_parts = [title_element.text] + [e.text + (e.tail if e.tail else \"\") for e in title_element.findall(\".//\")]\n",
    "                base_data['title'] = \"\".join(filter(None, title_parts))\n",
    "\n",
    "\n",
    "\n",
    "            # Extract author information\n",
    "            author_elements = root.findall(\".//tei:titleStmt/dhq:authorInfo\", namespaces=namespaces)\n",
    "\n",
    "            authors_data = []\n",
    "\n",
    "            for author_element in author_elements:\n",
    "                author_data = {}\n",
    "                \n",
    "                # Extract author name\n",
    "                author_name_element = author_element.find(\"dhq:author_name\", namespaces=namespaces)\n",
    "                if author_name_element is not None:\n",
    "                    first_name = author_name_element.text\n",
    "                    last_name_element = author_name_element.find(\"dhq:family\", namespaces=namespaces)\n",
    "                    if last_name_element is not None:\n",
    "                        full_name = f\"{first_name} {last_name_element.text}\".strip()\n",
    "                    else:\n",
    "                        full_name = first_name\n",
    "                    author_data['author_name'] = full_name\n",
    "\n",
    "                # Extract affiliation\n",
    "                affiliation_element = author_element.find(\"dhq:affiliation\", namespaces=namespaces)\n",
    "                if affiliation_element is not None:\n",
    "                    author_data['affiliation'] = affiliation_element.text\n",
    "\n",
    "                # Extract email\n",
    "                email_element = author_element.find(\"email\", namespaces=namespaces)\n",
    "                if email_element is not None:\n",
    "                    author_data['email'] = email_element.text\n",
    "\n",
    "                # Extract bio\n",
    "                bio_element = author_element.find(\"dhq:bio/tei:p\", namespaces=namespaces)\n",
    "                if bio_element is not None:\n",
    "                    author_data['bio'] = ''.join(bio_element.itertext()).strip()\n",
    "                \n",
    "                authors_data.append(author_data)\n",
    "\n",
    "            base_data['authors'] = authors_data\n",
    "\n",
    "            # Extracting paragraphs from the body\n",
    "            # Check if paragraphs are inside a <div> tag\n",
    "            # Get the <body> element\n",
    "            body_element = root.find(\".//tei:text/tei:body\", namespaces=namespaces)\n",
    "\n",
    "            # Extract all text from the <body> element and its descendants\n",
    "            body_text = ''.join(body_element.itertext()).strip()\n",
    "\n",
    "            base_data['body_text'] = body_text\n",
    "\n",
    "            # Then, instead of creating a separate dataframe for paragraphs, you can directly append the base_data dictionary to the all_data list:\n",
    "            data_df = pd.DataFrame([base_data])\n",
    "\n",
    "            all_data.append(data_df)\n",
    "\n",
    "        # Convert the data list to a DataFrame\n",
    "        final_df = pd.concat(all_data)\n",
    "        final_df.to_csv(output_path, index=False)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing XML files: 100%|██████████| 723/723 [00:01<00:00, 410.46it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "directory_path = \"../datasets/private_data/dhq/articles/\"\n",
    "all_data = []\n",
    "# xml_files = [os.path.join(directory_apth, file_name) for file_name in os.listdir(directory_apth) if file_name.endswith(\".xml\")]\n",
    "\n",
    "exclude = ['old', 'converted', 'dhq', 'sample', 'recovered', 'test', 'walsh']\n",
    "\n",
    "# List only XML files\n",
    "xml_files = [os.path.join(dp, f) for dp, dn, filenames in os.walk(directory_path) for f in filenames \n",
    "             if f.endswith('.xml') \n",
    "             and not any(ex_str in f for ex_str in exclude) \n",
    "             and not f.startswith('999')]\n",
    "\n",
    "\n",
    "df = process_xml_files(xml_files, '../datasets/private_data/dhq/reprocessed_dhq_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing XML files: 100%|██████████| 683/683 [00:01<00:00, 617.34it/s]\n"
     ]
    }
   ],
   "source": [
    "final_df = process_xml_files(xml_files, '../data/original_journal_datasets/dhq/dhq_data.csv')\n",
    "\n",
    "# Save the dataframe to a CSV file\n",
    "# final_df.to_csv('../data/original_journal_datasets/dhq/dhq_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=['DHQarticle-id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['000432', '000488', '000564', '000573', '000580', '000650',\n",
       "       '000657', '000664', '000677 ', '000709', '000712', '000714',\n",
       "       '000715', '000716', None], dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.volume.isna()]['DHQarticle-id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DHQarticle-id</th>\n",
       "      <th>volume</th>\n",
       "      <th>issue</th>\n",
       "      <th>articleType</th>\n",
       "      <th>date_when</th>\n",
       "      <th>dhq_keywords</th>\n",
       "      <th>language_ident</th>\n",
       "      <th>dhq_abstract</th>\n",
       "      <th>file_name</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>body_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000424</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>article</td>\n",
       "      <td>None</td>\n",
       "      <td>DHQ classification scheme; full list available...</td>\n",
       "      <td>en</td>\n",
       "      <td>Estudos recentes estão conseguindo demonstrar ...</td>\n",
       "      <td>../datasets/private_data/dhq/articles/000424/0...</td>\n",
       "      <td>SIG e história da arquitetura. Avances no\\n   ...</td>\n",
       "      <td>[{'author_name': 'Patricia\n",
       "                   ...</td>\n",
       "      <td>Introdução\\n                Os Sistemas de Inf...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  DHQarticle-id volume issue articleType date_when  \\\n",
       "0        000424   None  None     article      None   \n",
       "\n",
       "                                        dhq_keywords language_ident  \\\n",
       "0  DHQ classification scheme; full list available...             en   \n",
       "\n",
       "                                        dhq_abstract  \\\n",
       "0  Estudos recentes estão conseguindo demonstrar ...   \n",
       "\n",
       "                                           file_name  \\\n",
       "0  ../datasets/private_data/dhq/articles/000424/0...   \n",
       "\n",
       "                                               title  \\\n",
       "0  SIG e história da arquitetura. Avances no\\n   ...   \n",
       "\n",
       "                                             authors  \\\n",
       "0  [{'author_name': 'Patricia\n",
       "                   ...   \n",
       "\n",
       "                                           body_text  \n",
       "0  Introdução\\n                Os Sistemas de Inf...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['DHQarticle-id'] == \"000424\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.loc[final_df.file_name == \"../data/dhq_data/000664.xml\", \"volume\"] = \"016\"\n",
    "final_df.loc[final_df.file_name == \"../data/dhq_data/000664.xml\", \"issue\"] = \"4\"\n",
    "final_df.loc[final_df.file_name == \"../data/dhq_data/000684.xml\", \"volume\"] = \"017\"\n",
    "final_df.loc[final_df.file_name == \"../data/dhq_data/000684.xml\", \"issue\"] = \"2\"\n",
    "final_df.date_when = final_df.date_when.str.replace('Feburary', 'February')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['volume'] = final_df.volume.astype(int)\n",
    "final_df['issue'] = final_df.issue.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DHQarticle-id      0\n",
       "volume             0\n",
       "issue              0\n",
       "articleType        0\n",
       "date_when         12\n",
       "dhq_keywords       0\n",
       "language_ident     2\n",
       "dhq_abstract      21\n",
       "file_name          0\n",
       "title              0\n",
       "authors            0\n",
       "body_text          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DHQarticle-id      0\n",
       "volume            15\n",
       "issue             15\n",
       "articleType        0\n",
       "date              18\n",
       "dhq_keywords       0\n",
       "language_ident     2\n",
       "dhq_abstract      24\n",
       "file_name          0\n",
       "title              0\n",
       "authors            0\n",
       "body_text          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "older_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "older_df = older_df.rename(columns={'date_when': 'date'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(final_df, older_df[['DHQarticle-id', 'date']], on='DHQarticle-id', how='outer')\n",
    "merged_df = merged_df[merged_df.body_text.notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.loc[(merged_df.date_when != merged_df.date) & (merged_df.date_when.isna()), 'date_when'] = merged_df.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = merged_df.loc[(merged_df.date_when != merged_df.date) & (merged_df.date_when.isna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_links = pd.read_csv(\"../data/dhq_xml_links.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_links['file_name'] = \"../data/dhq_data/\" + xml_links.xml_link.str.split('/').str[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xml_link</th>\n",
       "      <th>volume</th>\n",
       "      <th>issue</th>\n",
       "      <th>DHQarticle-id</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>/dhq/vol/17/2/000673.xml</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>673</td>\n",
       "      <td>../data/dhq_data/000673.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>/dhq/vol/17/2/000673.xml</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>673</td>\n",
       "      <td>../data/dhq_data/000673.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>/dhq/vol/17/2/000680.xml</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>680</td>\n",
       "      <td>../data/dhq_data/000680.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>/dhq/vol/17/2/000680.xml</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>680</td>\n",
       "      <td>../data/dhq_data/000680.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>/dhq/vol/16/4/000664.xml</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>664</td>\n",
       "      <td>../data/dhq_data/000664.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>/dhq/vol/16/4/000664.xml</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>664</td>\n",
       "      <td>../data/dhq_data/000664.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>/dhq/vol/16/2/000646.xml</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>646</td>\n",
       "      <td>../data/dhq_data/000646.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>/dhq/vol/16/2/000646.xml</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>646</td>\n",
       "      <td>../data/dhq_data/000646.xml</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     xml_link  volume  issue  DHQarticle-id  \\\n",
       "46   /dhq/vol/17/2/000673.xml      17      2            673   \n",
       "47   /dhq/vol/17/2/000673.xml      17      2            673   \n",
       "48   /dhq/vol/17/2/000680.xml      17      2            680   \n",
       "49   /dhq/vol/17/2/000680.xml      17      2            680   \n",
       "102  /dhq/vol/16/4/000664.xml      16      4            664   \n",
       "103  /dhq/vol/16/4/000664.xml      16      4            664   \n",
       "152  /dhq/vol/16/2/000646.xml      16      2            646   \n",
       "153  /dhq/vol/16/2/000646.xml      16      2            646   \n",
       "\n",
       "                       file_name  \n",
       "46   ../data/dhq_data/000673.xml  \n",
       "47   ../data/dhq_data/000673.xml  \n",
       "48   ../data/dhq_data/000680.xml  \n",
       "49   ../data/dhq_data/000680.xml  \n",
       "102  ../data/dhq_data/000664.xml  \n",
       "103  ../data/dhq_data/000664.xml  \n",
       "152  ../data/dhq_data/000646.xml  \n",
       "153  ../data/dhq_data/000646.xml  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xml_links[xml_links.file_name.isin(missing.file_name)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['date_published'] = pd.to_datetime(merged_df['date_when'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DHQarticle-id</th>\n",
       "      <th>volume</th>\n",
       "      <th>issue</th>\n",
       "      <th>articleType</th>\n",
       "      <th>date_when</th>\n",
       "      <th>dhq_keywords</th>\n",
       "      <th>language_ident</th>\n",
       "      <th>dhq_abstract</th>\n",
       "      <th>file_name</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>body_text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>000680</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>article</td>\n",
       "      <td>None</td>\n",
       "      <td>DHQ classification scheme; full list available...</td>\n",
       "      <td>en</td>\n",
       "      <td>Southern Italian digital humanist Domenico Fio...</td>\n",
       "      <td>../data/dhq_data/000680.xml</td>\n",
       "      <td>Language,\\n               Materiality, and Dig...</td>\n",
       "      <td>[{'author_name': 'Cristina  Migliaccio', 'affi...</td>\n",
       "      <td>I shall try . . . to say something useful abou...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>000646</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>article</td>\n",
       "      <td>None</td>\n",
       "      <td>DHQ classification scheme; full list available...</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>../data/dhq_data/000646.xml</td>\n",
       "      <td>Introduction: The\\n               Questions of...</td>\n",
       "      <td>[{'author_name': 'Roopika  Risam', 'affiliatio...</td>\n",
       "      <td>Minimal computing is the answer. Minimal compu...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>000664</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>article</td>\n",
       "      <td>None</td>\n",
       "      <td>DHQ classification scheme; full list available...</td>\n",
       "      <td>en</td>\n",
       "      <td>The annual, international Digital Humanities c...</td>\n",
       "      <td>../data/dhq_data/000664.xml</td>\n",
       "      <td>Response to\\n\\t\\t\\t\\t\\t\\tThe circus we deserve...</td>\n",
       "      <td>[{'author_name': 'The Alliance of Digital Huma...</td>\n",
       "      <td>Executive Summary \\n\\t\\t\\t\\t\\tWe thank DHQ for...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>000673</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>article</td>\n",
       "      <td>None</td>\n",
       "      <td>DHQ classification scheme; full list available...</td>\n",
       "      <td>en</td>\n",
       "      <td>A novel, rule-based, automatic framework for i...</td>\n",
       "      <td>../data/dhq_data/000673.xml</td>\n",
       "      <td>Automatic\\n               Identification of Rh...</td>\n",
       "      <td>[{'author_name': 'Heyam  Abd Alhadi', 'affilia...</td>\n",
       "      <td>1. Introduction\\n            Rhetoric, balāgha...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    DHQarticle-id  volume  issue articleType date_when  \\\n",
       "184        000680    17.0    2.0     article      None   \n",
       "334        000646    16.0    2.0     article      None   \n",
       "459        000664    16.0    4.0     article      None   \n",
       "498        000673    17.0    2.0     article      None   \n",
       "\n",
       "                                          dhq_keywords language_ident  \\\n",
       "184  DHQ classification scheme; full list available...             en   \n",
       "334  DHQ classification scheme; full list available...             en   \n",
       "459  DHQ classification scheme; full list available...             en   \n",
       "498  DHQ classification scheme; full list available...             en   \n",
       "\n",
       "                                          dhq_abstract  \\\n",
       "184  Southern Italian digital humanist Domenico Fio...   \n",
       "334                                               None   \n",
       "459  The annual, international Digital Humanities c...   \n",
       "498  A novel, rule-based, automatic framework for i...   \n",
       "\n",
       "                       file_name  \\\n",
       "184  ../data/dhq_data/000680.xml   \n",
       "334  ../data/dhq_data/000646.xml   \n",
       "459  ../data/dhq_data/000664.xml   \n",
       "498  ../data/dhq_data/000673.xml   \n",
       "\n",
       "                                                 title  \\\n",
       "184  Language,\\n               Materiality, and Dig...   \n",
       "334  Introduction: The\\n               Questions of...   \n",
       "459  Response to\\n\\t\\t\\t\\t\\t\\tThe circus we deserve...   \n",
       "498  Automatic\\n               Identification of Rh...   \n",
       "\n",
       "                                               authors  \\\n",
       "184  [{'author_name': 'Cristina  Migliaccio', 'affi...   \n",
       "334  [{'author_name': 'Roopika  Risam', 'affiliatio...   \n",
       "459  [{'author_name': 'The Alliance of Digital Huma...   \n",
       "498  [{'author_name': 'Heyam  Abd Alhadi', 'affilia...   \n",
       "\n",
       "                                             body_text  date  \n",
       "184  I shall try . . . to say something useful abou...  None  \n",
       "334  Minimal computing is the answer. Minimal compu...  None  \n",
       "459  Executive Summary \\n\\t\\t\\t\\t\\tWe thank DHQ for...  None  \n",
       "498  1. Introduction\\n            Rhetoric, balāgha...  None  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/dhq_data/000680.xml\n",
      "17.0 2.0\n",
      "2023-07-20 00:00:00\n",
      "../data/dhq_data/000646.xml\n",
      "16.0 2.0\n",
      "2022-06-25 00:00:00\n",
      "../data/dhq_data/000664.xml\n",
      "16.0 4.0\n",
      "2022-10-14 00:00:00\n",
      "../data/dhq_data/000673.xml\n",
      "17.0 2.0\n",
      "2023-07-20 00:00:00\n"
     ]
    }
   ],
   "source": [
    "for _, row in missing.iterrows():\n",
    "    print(row.file_name)\n",
    "    vol = row['volume']\n",
    "    issue = row['issue']\n",
    "    print(vol, issue)\n",
    "    date = merged_df[(merged_df.volume == vol) & (merged_df.issue == issue)].sort_values(by='date_published', ascending=False).iloc[0].date_published\n",
    "    print(date)\n",
    "    merged_df.loc[(merged_df.file_name == row.file_name), 'date_published'] = date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DHQarticle-id      0\n",
       "volume             0\n",
       "issue              0\n",
       "articleType        0\n",
       "date_when          4\n",
       "dhq_keywords       0\n",
       "language_ident     2\n",
       "dhq_abstract      21\n",
       "file_name          0\n",
       "title              0\n",
       "authors            0\n",
       "body_text          0\n",
       "date               4\n",
       "date_published     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('../data/original_journal_datasets/dhq/dhq_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-work-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
